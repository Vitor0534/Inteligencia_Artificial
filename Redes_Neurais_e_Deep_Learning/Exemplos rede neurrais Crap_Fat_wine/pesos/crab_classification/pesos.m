function [Y,Xf,Af] = myNeuralNetworkFunction(X,~,~)
%MYNEURALNETWORKFUNCTION neural network simulation function.
%
% Generated by Neural Network Toolbox function genFunction, 30-Nov-2019 00:16:07.
%
% [Y] = myNeuralNetworkFunction(X,~,~) takes these arguments:
%
%   X = 1xTS cell, 1 inputs over TS timesteps
%   Each X{1,ts} = 6xQ matrix, input #1 at timestep ts.
%
% and returns:
%   Y = 1xTS cell of 1 outputs over TS timesteps.
%   Each Y{1,ts} = 2xQ matrix, output #1 at timestep ts.
%
% where Q is number of samples (or series) and TS is the number of timesteps.

%#ok<*RPMT0>

% ===== NEURAL NETWORK CONSTANTS =====

% Input 1
x1_step1.xoffset = [0;7.2;6.5;14.7;17.1;6.1];
x1_step1.gain = [2;0.125786163522013;0.145985401459854;0.060790273556231;0.0533333333333333;0.129032258064516];
x1_step1.ymin = -1;

% Layer 1
b1 = [-2.6347371937296997224;-3.5539006576440184126;1.8696603566408316333;1.3027842876548116902;1.1631838938763197078;0.47585160936477066684;0.64701157035985390475;2.4572729032948830152;-3.9658154701411651999;0.62672019434539916194];
IW1_1 = [0.040964472491735695603 0.89557572114651939899 -0.65997716338812384418 1.6755272211266887261 0.51437004968510058323 0.31298471587341064604;-0.90395766254463094658 -0.67905946115277038277 0.53942948838479864992 -0.4726462271221580913 0.48823555069535906625 1.3620064622096121898;-0.49717006213579895135 -1.190946437128694857 -0.84846477658298713465 0.59400656392868456113 0.46015533735621461098 0.46784586264174665704;-0.11648009817490229123 3.823754586210299955 7.9962086854689449211 -5.7993754477925829605 -3.0537544906976883397 -1.3387863080876003519;0.07547810577154195899 1.3459809127634860815 1.261810740669770059 -2.1514984759805315662 0.15250481185952982632 -0.4363249486343235839;-0.68226245592925827133 -1.489677598515929402 -5.0376058899678604064 2.8129907699454044234 3.0540120822418401758 1.2153164872412673958;-1.1125071774183854512 -0.18174561385964813076 -2.5279791854060174039 0.08835260790552729171 -0.86910454382319402011 -1.8180149268556720088;0.065046872062236846257 -0.90990162681548325541 -1.0570803779336352957 0.091671017832698556416 0.42548208485720429017 -0.46616814220223118381;1.6731453838601839657 0.33952722803049645295 0.59878698838366350987 -0.76330357238682067234 -1.4343710268110976269 -1.3331823267015650014;0.085830352928076045216 -1.5106518124758983035 -1.9574441610479149656 0.67053589560110871126 -1.7995463238621645097 0.29246326132535988007];

% Layer 2
b2 = [-0.25231160054705920048;-0.18859902176179607625];
LW2_1 = [-1.1546604534666806696 -0.82388058517182161111 0.49736857021436631232 8.8607070541251289342 1.0685320653876986263 -3.9573687631094451866 -1.3394872504542771896 1.1502529879039253835 1.7784147099599592057 -1.432387717626790069;0.8341568085687111056 0.35914192697464997206 -0.66326780418050668153 -7.9859748621976915928 -1.9998061123888364321 4.2419974235464206203 1.2958772433718186434 -0.081298684130036547035 -2.7367071129027045195 1.5694894196980591072];

% ===== SIMULATION ========

% Format Input Arguments
isCellX = iscell(X);
if ~isCellX
    X = {X};
end

% Dimensions
TS = size(X,2); % timesteps
if ~isempty(X)
    Q = size(X{1},2); % samples/series
else
    Q = 0;
end

% Allocate Outputs
Y = cell(1,TS);

% Time loop
for ts=1:TS
    
    % Input 1
    Xp1 = mapminmax_apply(X{1,ts},x1_step1);
    
    % Layer 1
    a1 = tansig_apply(repmat(b1,1,Q) + IW1_1*Xp1);
    
    % Layer 2
    a2 = softmax_apply(repmat(b2,1,Q) + LW2_1*a1);
    
    % Output 1
    Y{1,ts} = a2;
end

% Final Delay States
Xf = cell(1,0);
Af = cell(2,0);

% Format Output Arguments
if ~isCellX
    Y = cell2mat(Y);
end
end

% ===== MODULE FUNCTIONS ========

% Map Minimum and Maximum Input Processing Function
function y = mapminmax_apply(x,settings)
y = bsxfun(@minus,x,settings.xoffset);
y = bsxfun(@times,y,settings.gain);
y = bsxfun(@plus,y,settings.ymin);
end

% Competitive Soft Transfer Function
function a = softmax_apply(n,~)
if isa(n,'gpuArray')
    a = iSoftmaxApplyGPU(n);
else
    a = iSoftmaxApplyCPU(n);
end
end
function a = iSoftmaxApplyCPU(n)
nmax = max(n,[],1);
n = bsxfun(@minus,n,nmax);
numerator = exp(n);
denominator = sum(numerator,1);
denominator(denominator == 0) = 1;
a = bsxfun(@rdivide,numerator,denominator);
end
function a = iSoftmaxApplyGPU(n)
nmax = max(n,[],1);
numerator = arrayfun(@iSoftmaxApplyGPUHelper1,n,nmax);
denominator = sum(numerator,1);
a = arrayfun(@iSoftmaxApplyGPUHelper2,numerator,denominator);
end
function numerator = iSoftmaxApplyGPUHelper1(n,nmax)
numerator = exp(n - nmax);
end
function a = iSoftmaxApplyGPUHelper2(numerator,denominator)
if (denominator == 0)
    a = numerator;
else
    a = numerator ./ denominator;
end
end

% Sigmoid Symmetric Transfer Function
function a = tansig_apply(n,~)
a = 2 ./ (1 + exp(-2*n)) - 1;
end
